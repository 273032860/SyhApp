import {
  Break,
  Continue,
  Fn,
  If,
  Loop,
  abs,
  convertToTexture,
  cross,
  div,
  dot,
  float,
  getScreenPosition,
  getViewPosition,
  int,
  logarithmicDepthToViewZ,
  max,
  mul,
  nodeObject,
  normalize,
  orthographicDepthToViewZ,
  passTexture,
  perspectiveDepthToViewZ,
  premultiplyAlpha,
  reference,
  reflect,
  screenCoordinate,
  sqrt,
  sub,
  texture,
  textureSize,
  uniform,
  unpremultiplyAlpha,
  uv,
  vec2,
  vec3,
  vec4,
  viewZToPerspectiveDepth
} from "./chunk-NKTWHCJT.js";
import {
  NodeMaterial,
  NodeUpdateType,
  QuadMesh,
  RendererUtils,
  TempNode
} from "./chunk-5FFPRNLG.js";
import {
  HalfFloatType,
  LinearFilter,
  LinearMipmapLinearFilter,
  RenderTarget,
  Vector2
} from "./chunk-GHUIN7QU.js";
import "./chunk-G3PMV62Z.js";

// node_modules/three/examples/jsm/tsl/display/boxBlur.js
var boxBlur = Fn(([textureNode, options = {}]) => {
  textureNode = convertToTexture(textureNode);
  const size = nodeObject(options.size) || int(1);
  const separation = nodeObject(options.separation) || int(1);
  const premultipliedAlpha = options.premultipliedAlpha || false;
  const tap = (uv2) => {
    const sample = textureNode.sample(uv2);
    return premultipliedAlpha ? premultiplyAlpha(sample) : sample;
  };
  const targetUV = textureNode.uvNode || uv();
  const result = vec4(0);
  const sep = max(separation, 1);
  const count = int(0);
  const pixelStep = vec2(1).div(textureSize(textureNode));
  Loop({ start: size.negate(), end: size, name: "i", condition: "<=" }, ({ i }) => {
    Loop({ start: size.negate(), end: size, name: "j", condition: "<=" }, ({ j }) => {
      const uvs = targetUV.add(vec2(i, j).mul(pixelStep).mul(sep));
      result.addAssign(tap(uvs));
      count.addAssign(1);
    });
  });
  result.divAssign(count);
  return premultipliedAlpha ? unpremultiplyAlpha(result) : result;
});

// node_modules/three/examples/jsm/tsl/display/SSRNode.js
var _quadMesh = new QuadMesh();
var _size = new Vector2();
var _rendererState;
var SSRNode = class extends TempNode {
  static get type() {
    return "SSRNode";
  }
  /**
   * Constructs a new SSR node.
   *
   * @param {Node<vec4>} colorNode - The node that represents the beauty pass.
   * @param {Node<float>} depthNode - A node that represents the beauty pass's depth.
   * @param {Node<vec3>} normalNode - A node that represents the beauty pass's normals.
   * @param {Node<float>} metalnessNode - A node that represents the beauty pass's metalness.
   * @param {?Node<float>} [roughnessNode=null] - A node that represents the beauty pass's roughness.
   * @param {?Camera} [camera=null] - The camera the scene is rendered with.
   */
  constructor(colorNode, depthNode, normalNode, metalnessNode, roughnessNode = null, camera = null) {
    super("vec4");
    this.colorNode = colorNode;
    this.depthNode = depthNode;
    this.normalNode = normalNode;
    this.metalnessNode = metalnessNode;
    this.roughnessNode = roughnessNode;
    this.resolutionScale = 1;
    this.updateBeforeType = NodeUpdateType.FRAME;
    this.maxDistance = uniform(1);
    this.thickness = uniform(0.1);
    this.opacity = uniform(1);
    this.quality = uniform(0.5);
    this.blurQuality = uniform(2);
    if (camera === null) {
      if (this.colorNode.passNode && this.colorNode.passNode.isPassNode === true) {
        camera = this.colorNode.passNode.camera;
      } else {
        throw new Error("THREE.TSL: No camera found. ssr() requires a camera.");
      }
    }
    this.camera = camera;
    this._blurSpread = uniform(1);
    this._cameraProjectionMatrix = uniform(camera.projectionMatrix);
    this._cameraProjectionMatrixInverse = uniform(camera.projectionMatrixInverse);
    this._cameraNear = reference("near", "float", camera);
    this._cameraFar = reference("far", "float", camera);
    this._isPerspectiveCamera = uniform(camera.isPerspectiveCamera);
    this._resolution = uniform(new Vector2());
    this._ssrRenderTarget = new RenderTarget(1, 1, { depthBuffer: false, type: HalfFloatType });
    this._ssrRenderTarget.texture.name = "SSRNode.SSR";
    this._blurRenderTarget = new RenderTarget(1, 1, { depthBuffer: false, type: HalfFloatType, minFilter: LinearMipmapLinearFilter, magFilter: LinearFilter });
    this._blurRenderTarget.texture.name = "SSRNode.Blur";
    this._blurRenderTarget.texture.mipmaps.push({}, {}, {}, {}, {});
    this._ssrMaterial = new NodeMaterial();
    this._ssrMaterial.name = "SSRNode.SSR";
    this._blurMaterial = new NodeMaterial();
    this._blurMaterial.name = "SSRNode.Blur";
    this._copyMaterial = new NodeMaterial();
    this._copyMaterial.name = "SSRNode.Copy";
    this._textureNode = passTexture(this, this._ssrRenderTarget.texture);
    let blurredTextureNode = null;
    if (this.roughnessNode !== null) {
      const mips = this._blurRenderTarget.texture.mipmaps.length - 1;
      const lod = float(this.roughnessNode).mul(mips).clamp(0, mips);
      blurredTextureNode = passTexture(this, this._blurRenderTarget.texture).level(lod);
    }
    this._blurredTextureNode = blurredTextureNode;
  }
  /**
   * Returns the result of the effect as a texture node.
   *
   * @return {PassTextureNode} A texture node that represents the result of the effect.
   */
  getTextureNode() {
    return this.roughnessNode !== null ? this._blurredTextureNode : this._textureNode;
  }
  /**
   * Sets the size of the effect.
   *
   * @param {number} width - The width of the effect.
   * @param {number} height - The height of the effect.
   */
  setSize(width, height) {
    width = Math.round(this.resolutionScale * width);
    height = Math.round(this.resolutionScale * height);
    this._resolution.value.set(width, height);
    this._ssrRenderTarget.setSize(width, height);
    this._blurRenderTarget.setSize(width, height);
  }
  /**
   * This method is used to render the effect once per frame.
   *
   * @param {NodeFrame} frame - The current node frame.
   */
  updateBefore(frame) {
    const { renderer } = frame;
    _rendererState = RendererUtils.resetRendererState(renderer, _rendererState);
    const ssrRenderTarget = this._ssrRenderTarget;
    const blurRenderTarget = this._blurRenderTarget;
    const size = renderer.getDrawingBufferSize(_size);
    _quadMesh.material = this._ssrMaterial;
    this.setSize(size.width, size.height);
    renderer.setMRT(null);
    renderer.setClearColor(0, 0);
    renderer.setRenderTarget(ssrRenderTarget);
    _quadMesh.render(renderer);
    if (this.roughnessNode !== null) {
      for (let i = 0; i < blurRenderTarget.texture.mipmaps.length; i++) {
        _quadMesh.material = i === 0 ? this._copyMaterial : this._blurMaterial;
        this._blurSpread.value = i;
        renderer.setRenderTarget(blurRenderTarget, 0, i);
        _quadMesh.render(renderer);
      }
    }
    RendererUtils.restoreRendererState(renderer, _rendererState);
  }
  /**
   * This method is used to setup the effect's TSL code.
   *
   * @param {NodeBuilder} builder - The current node builder.
   * @return {PassTextureNode}
   */
  setup(builder) {
    const uvNode = uv();
    const pointToLineDistance = Fn(([point, linePointA, linePointB]) => {
      return cross(point.sub(linePointA), point.sub(linePointB)).length().div(linePointB.sub(linePointA).length());
    });
    const pointPlaneDistance = Fn(([point, planePoint, planeNormal]) => {
      const d = mul(planeNormal.x, planePoint.x).add(mul(planeNormal.y, planePoint.y)).add(mul(planeNormal.z, planePoint.z)).negate().toVar();
      const denominator = sqrt(mul(planeNormal.x, planeNormal.x).add(mul(planeNormal.y, planeNormal.y)).add(mul(planeNormal.z, planeNormal.z))).toVar();
      const distance = div(mul(planeNormal.x, point.x).add(mul(planeNormal.y, point.y)).add(mul(planeNormal.z, point.z)).add(d), denominator);
      return distance;
    });
    const getViewZ = Fn(([depth]) => {
      let viewZNode;
      if (this.camera.isPerspectiveCamera) {
        viewZNode = perspectiveDepthToViewZ(depth, this._cameraNear, this._cameraFar);
      } else {
        viewZNode = orthographicDepthToViewZ(depth, this._cameraNear, this._cameraFar);
      }
      return viewZNode;
    });
    const sampleDepth = (uv2) => {
      const depth = this.depthNode.sample(uv2).r;
      if (builder.renderer.logarithmicDepthBuffer === true) {
        const viewZ = logarithmicDepthToViewZ(depth, this._cameraNear, this._cameraFar);
        return viewZToPerspectiveDepth(viewZ, this._cameraNear, this._cameraFar);
      }
      return depth;
    };
    const ssr2 = Fn(() => {
      const metalness = float(this.metalnessNode);
      metalness.equal(0).discard();
      const depth = sampleDepth(uvNode).toVar();
      const viewPosition = getViewPosition(uvNode, depth, this._cameraProjectionMatrixInverse).toVar();
      const viewNormal = this.normalNode.rgb.normalize().toVar();
      const viewIncidentDir = (this.camera.isPerspectiveCamera ? normalize(viewPosition) : vec3(0, 0, -1)).toVar();
      const viewReflectDir = reflect(viewIncidentDir, viewNormal).toVar();
      const maxReflectRayLen = this.maxDistance.div(dot(viewIncidentDir.negate(), viewNormal)).toVar();
      const d1viewPosition = viewPosition.add(viewReflectDir.mul(maxReflectRayLen)).toVar();
      If(this._isPerspectiveCamera.and(d1viewPosition.z.greaterThan(this._cameraNear.negate())), () => {
        const t = sub(this._cameraNear.negate(), viewPosition.z).div(viewReflectDir.z);
        d1viewPosition.assign(viewPosition.add(viewReflectDir.mul(t)));
      });
      const d0 = screenCoordinate.xy.toVar();
      const d1 = getScreenPosition(d1viewPosition, this._cameraProjectionMatrix).mul(this._resolution).toVar();
      const totalLen = d1.sub(d0).length().toVar();
      const xLen = d1.x.sub(d0.x).toVar();
      const yLen = d1.y.sub(d0.y).toVar();
      const totalStep = int(max(abs(xLen), abs(yLen)).mul(this.quality.clamp())).toConst();
      const xSpan = xLen.div(totalStep).toVar();
      const ySpan = yLen.div(totalStep).toVar();
      const output = vec4(0).toVar();
      Loop(totalStep, ({ i }) => {
        const xy = vec2(d0.x.add(xSpan.mul(float(i))), d0.y.add(ySpan.mul(float(i)))).toVar();
        If(xy.x.lessThan(0).or(xy.x.greaterThan(this._resolution.x)).or(xy.y.lessThan(0)).or(xy.y.greaterThan(this._resolution.y)), () => {
          Break();
        });
        const uvNode2 = xy.div(this._resolution);
        const d = sampleDepth(uvNode2).toVar();
        const vZ = getViewZ(d).toVar();
        const viewReflectRayZ = float(0).toVar();
        const s = xy.sub(d0).length().div(totalLen);
        If(this._isPerspectiveCamera, () => {
          const recipVPZ = float(1).div(viewPosition.z).toVar();
          viewReflectRayZ.assign(float(1).div(recipVPZ.add(s.mul(float(1).div(d1viewPosition.z).sub(recipVPZ)))));
        }).Else(() => {
          viewReflectRayZ.assign(viewPosition.z.add(s.mul(d1viewPosition.z.sub(viewPosition.z))));
        });
        If(viewReflectRayZ.lessThanEqual(vZ), () => {
          const vP = getViewPosition(uvNode2, d, this._cameraProjectionMatrixInverse).toVar();
          const away = pointToLineDistance(vP, viewPosition, d1viewPosition).toVar();
          const xyNeighbor = vec2(xy.x.add(1), xy.y).toVar();
          const uvNeighbor = xyNeighbor.div(this._resolution);
          const vPNeighbor = getViewPosition(uvNeighbor, d, this._cameraProjectionMatrixInverse).toVar();
          const minThickness = vPNeighbor.x.sub(vP.x).toVar();
          minThickness.mulAssign(3);
          const tk = max(minThickness, this.thickness).toVar();
          If(away.lessThanEqual(tk), () => {
            const vN = this.normalNode.sample(uvNode2).rgb.normalize().toVar();
            If(dot(viewReflectDir, vN).greaterThanEqual(0), () => {
              Continue();
            });
            const distance = pointPlaneDistance(vP, viewPosition, viewNormal).toVar();
            If(distance.greaterThan(this.maxDistance), () => {
              Break();
            });
            const op = this.opacity.mul(metalness).toVar();
            const ratio = float(1).sub(distance.div(this.maxDistance)).toVar();
            const attenuation = ratio.mul(ratio);
            op.mulAssign(attenuation);
            const fresnelCoe = div(dot(viewIncidentDir, viewReflectDir).add(1), 2);
            op.mulAssign(fresnelCoe);
            const reflectColor = this.colorNode.sample(uvNode2);
            output.assign(vec4(reflectColor.rgb, op));
            Break();
          });
        });
      });
      return output;
    });
    this._ssrMaterial.fragmentNode = ssr2().context(builder.getSharedContext());
    this._ssrMaterial.needsUpdate = true;
    const reflectionBuffer = texture(this._ssrRenderTarget.texture);
    this._blurMaterial.fragmentNode = boxBlur(reflectionBuffer, { size: this.blurQuality, separation: this._blurSpread });
    this._blurMaterial.needsUpdate = true;
    this._copyMaterial.fragmentNode = reflectionBuffer;
    this._copyMaterial.needsUpdate = true;
    return this.getTextureNode();
  }
  /**
   * Frees internal resources. This method should be called
   * when the effect is no longer required.
   */
  dispose() {
    this._ssrRenderTarget.dispose();
    this._blurRenderTarget.dispose();
    this._ssrMaterial.dispose();
    this._blurMaterial.dispose();
    this._copyMaterial.dispose();
  }
};
var SSRNode_default = SSRNode;
var ssr = (colorNode, depthNode, normalNode, metalnessNode, roughnessNode = null, camera = null) => nodeObject(new SSRNode(nodeObject(colorNode), nodeObject(depthNode), nodeObject(normalNode), nodeObject(metalnessNode), nodeObject(roughnessNode), camera));
export {
  SSRNode_default as default,
  ssr
};
//# sourceMappingURL=three_addons_tsl_display_SSRNode__js.js.map
